{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "\n",
    "~~Train&Test~~\n",
    "- ~~split the dataset into train and test~~\n",
    "- ~~drop the lables that are not working!~~\n",
    "\n",
    "~~Inputs&Labels~~\n",
    "- ~~mix the labels and input orders (all of them are [0,1])~~\n",
    "\n",
    "Articles&Tenses\n",
    "- Remove the articles and present tense verbs - Maunally :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import ast\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lambeq.backend.grammar import Ty, Box \n",
    "from lambeq import BobcatParser, AtomicType, Sim14Ansatz, RemoveCupsRewriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(\"(*) All libraries are successfully imported!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset and label into trainign and testing similar to the pennyland model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# ==============================================\n",
    "\n",
    "# Specify the folder and file name\n",
    "folder_name = \"Features-Datasets\"\n",
    "file_name = \"features_dataset_1.csv\"\n",
    "\n",
    "# Construct the file path\n",
    "file_path = os.path.join(os.getcwd(), folder_name, file_name)\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "# filename = \"trial_feature_extraction.csv\"   # Trained Bert X Resnet Epochs loop\n",
    "# filename = \"features_dataset.csv\"         # Trained Resnet once\n",
    "# file_path = os.path.join(os.getcwd(), filename)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the sentence\n",
    "sentence = df['sentence']\n",
    "image_1 = df['image_1']\n",
    "image_2 = df['image_2']\n",
    "label_image1 = df['label_image1']\n",
    "label_image2 = df['label_image2']\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': sentence,\n",
    "    'image_1': image_1,\n",
    "    'image_2': image_2,\n",
    "    'label_image1': label_image1,\n",
    "    'label_image2': label_image2\n",
    "})\n",
    "\n",
    "# Make the image_1 and image_2 into float lists instead of strings\n",
    "df[\"image_1\"] = df[\"image_1\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "df[\"image_2\"] = df[\"image_2\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# ============= TODO: =============\n",
    "# RE ORDER THE LABELS AND IMAGES!\n",
    "\n",
    "print(f\" Length of dataframe: {len(df)}\")\n",
    "\n",
    "n = random.randint(80, 120) # Number of indicies to swap\n",
    "print( \" Amount of indicies to swap: \", n)\n",
    "\n",
    "index_to_swap = random.sample(range(0, len(df) + 1), n)\n",
    "# print(f\" Random Indicies to swap: \\n{index_to_swap}\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index in index_to_swap:\n",
    "        # print(f\" Index {index}: swapping\")\n",
    "        # Swap imags and labels\n",
    "        df.at[index, 'image_1'], df.at[index, 'image_2'] = df.at[index, 'image_2'], df.at[index, 'image_1']\n",
    "        df.at[index, 'label_image1'], df.at[index, 'label_image2'] = df.at[index, 'label_image2'], df.at[index, 'label_image1']\n",
    "\n",
    "print(\"(*) Completed swapping the values of random n labels. \\n\")\n",
    "\n",
    "# =================================\n",
    "\n",
    "# First split: train and combined validation/test set\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: validation and test set\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Print the sizes of each set to verify\n",
    "print(f\" Training set size: {len(train_df)}\")\n",
    "print(f\" Validation set size: {len(val_df)}\")\n",
    "print(f\" Test set size: {len(test_df)}\")\n",
    "\n",
    "\n",
    "print(\"(*) Data Extracted!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences Diagram & Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# CREATE SENTENCE DIAGRAMS\n",
    "# ==============================================\n",
    "\n",
    "remove_cups = RemoveCupsRewriter()\n",
    "\n",
    "# Parse the sentence \n",
    "train_sentences = train_df[\"sentence\"]\n",
    "val_sentences = val_df[\"sentence\"]\n",
    "test_sentences = test_df[\"sentence\"]\n",
    "\n",
    "# Use BobbcatParser to convert it into a string diagram\n",
    "print(\" parsing sentences ..\")\n",
    "parser = BobcatParser(verbose='suppress')\n",
    "print(\".\")\n",
    "raw_train_sentence_diagrams = [parser.sentence2diagram(sentence) for sentence in train_sentences]\n",
    "raw_val_sentence_diagrams = [parser.sentence2diagram(sentence) for sentence in val_sentences]\n",
    "raw_test_sentence_diagrams = [parser.sentence2diagram(sentence) for sentence in test_sentences]\n",
    "# --------\n",
    "print(\" ↓ example senetnce diagram from train dataset\")\n",
    "raw_train_sentence_diagrams[1].draw(figsize=(14, 3), fontsize=12)\n",
    "# --------\n",
    "\n",
    "# Use remove cups to decrease the number of wires used\n",
    "print(\" creating diagrams ..\")\n",
    "train_diagrams_sentence = [remove_cups(sentence_diagram) for sentence_diagram in raw_train_sentence_diagrams]\n",
    "val_diagrams_sentence = [remove_cups(sentence_diagram) for sentence_diagram in raw_val_sentence_diagrams]\n",
    "test_diagrams_sentence = [remove_cups(sentence_diagram) for sentence_diagram in raw_test_sentence_diagrams]\n",
    "# --------\n",
    "print(' ↓ sample sentence diagram without cups from train dataset')\n",
    "train_diagrams_sentence[1].draw()\n",
    "# --------\n",
    "\n",
    "ansatz_sentence = Sim14Ansatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1, AtomicType.PREPOSITIONAL_PHRASE: 1},n_layers=1)\n",
    "\n",
    "train_circuits_sentence = [ansatz_sentence(diagram) for diagram in train_diagrams_sentence]\n",
    "val_circuits_sentence = [ansatz_sentence(diagram) for diagram in val_diagrams_sentence]\n",
    "test_circuits_sentence = [ansatz_sentence(diagram) for diagram in test_diagrams_sentence]\n",
    "# --------\n",
    "print(' ↓ sample sentence circuit from train dataset')\n",
    "train_circuits_sentence[1].draw(figsize=(30, 20), fontsize=12)\n",
    "# --------\n",
    "\n",
    "print(\"(*) Ansatz created for all senetnces!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Diagram & Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_box.draw(figsize=(14, 3), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new image Ty\n",
    "image_type = Ty(\"image\")\n",
    "image_box = Box(name = \"IMAGE\", dom = Ty(), cod= image_type)\n",
    "# image_box.draw(figsize=(14, 3), fontsize=12)\n",
    "\n",
    "# Create template Ansatz\n",
    "ansatz = Sim14Ansatz({image_type: 4}, n_layers=1)\n",
    "image_circ = ansatz(image_box)\n",
    "# print('↓ template image circuit')\n",
    "# image_circ.draw(figsize=(20, 10), fontsize=12)\n",
    "\n",
    "# Add data into image circuit POSITIVE\n",
    "train_images_1 = train_df[\"image_1\"]\n",
    "val_images_1 = val_df[\"image_1\"]\n",
    "test_images_1 = test_df[\"image_1\"]\n",
    "\n",
    "train_circuits_image1 = [image_circ.lambdify(*list(image_circ.free_symbols))(*feature_vec) for feature_vec in train_images_1]\n",
    "val_circuits_image1 = [image_circ.lambdify(*list(image_circ.free_symbols))(*feature_vec) for feature_vec in val_images_1]\n",
    "test_circuits_image1 = [image_circ.lambdify(*list(image_circ.free_symbols))(*feature_vec) for feature_vec in test_images_1]\n",
    "print(\" Complete: circuits for positive image\")\n",
    "#  --------\n",
    "print(' ↓ sample sentence diagram without cups from train dataset')\n",
    "train_circuits_image1[1].draw(figsize=(20, 10), fontsize=12)\n",
    "#  --------\n",
    "\n",
    "# Add data into image circuit NEGATIVE\n",
    "train_images_2 = train_df[\"image_2\"]\n",
    "val_images_2 = val_df[\"image_2\"]\n",
    "test_images_2 = test_df[\"image_2\"]\n",
    "\n",
    "train_circuits_image2 = [image_circ.lambdify(*list(image_circ.free_symbols))(*feature_vec) for feature_vec in train_images_2]\n",
    "val_circuits_image2 = [image_circ.lambdify(*list(image_circ.free_symbols))(*feature_vec) for feature_vec in val_images_2]\n",
    "test_circuits_image2 = [image_circ.lambdify(*list(image_circ.free_symbols))(*feature_vec) for feature_vec in test_images_2]\n",
    "print(\" Complete: circuit for negative images\")\n",
    "#  --------\n",
    "train_circuits_image2[1].draw(figsize=(20, 10), fontsize=12)\n",
    "#  --------\n",
    "\n",
    "print(\"(*) Circuits and digrams created for all images!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined for Sentence & Images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING:\n",
    "- ONLY RUN THIS CODE ONCE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagram template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FINAL CIRCUIT\n",
    "\n",
    "def generate_valid_diagrams(diagram_sentence, df):\n",
    "    print(\"************************\")\n",
    "    indicies_to_drop= []\n",
    "    conc_diagrams = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            temp = diagram_sentence[index] @ image_type @ image_type >> comparison_box\n",
    "            conc_diagrams.append(temp)\n",
    "        except Exception as e:\n",
    "            # print(f\"Error at index in diagram sentence {index}: {e}\")\n",
    "            # print( \"    \",df[\"sentence\"].iloc[index])\n",
    "            indicies_to_drop.append(index)\n",
    "    # print(\"************************\")\n",
    "\n",
    "    # print(\"************************\")\n",
    "    for index, row in df.iterrows():\n",
    "        if index in indicies_to_drop:\n",
    "            # print(\"Removing index: \", index)\n",
    "            df = df.drop(index = index)\n",
    "    # print(\"************************\")\n",
    "\n",
    "    print(\"Dropped the following indicies:\", indicies_to_drop)\n",
    "    \n",
    "    return df, conc_diagrams\n",
    "\n",
    "# Create new Type\n",
    "output_type = Ty(\"output\")\n",
    "comparison_box = Box(\"COMPARISON\", AtomicType.SENTENCE @ image_type @ image_type, output_type)\n",
    "\n",
    "# Draws diagram with comparison box (0,1) - Sentence digram and comparison box is in grammar form\n",
    "\n",
    "train_df, train_conc_diagrams = generate_valid_diagrams(train_diagrams_sentence, train_df)\n",
    "val_df, val_conc_diagrams = generate_valid_diagrams(val_diagrams_sentence, val_df)\n",
    "test_df, test_conc_diagrams = generate_valid_diagrams(test_diagrams_sentence, test_df)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(\"CHCEKING:\")\n",
    "print(f\"    124 -> {len(train_df)} == {len(train_conc_diagrams)}\")\n",
    "print(f\"    29 -> {len(val_df)} == {len(val_conc_diagrams)}\")\n",
    "print(f\"    31 -> {len(test_df)} == {len(test_conc_diagrams)}\")\n",
    "\n",
    "print(' ↓ template merged diagram : (sentence, image1, image2)')\n",
    "train_conc_diagrams[15].draw(figsize=(20, 10), fontsize=12)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"\\n(*) Train: {len(train_conc_diagrams)} diagrams completed successfully!\")\n",
    "print(f\"(*) Val: {len(val_conc_diagrams)} diagrams completed successfully!\")\n",
    "print(f\"(*) Test: {len(test_conc_diagrams)} diagrams completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Circuit Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ansatz & Circuit\n",
    "ansatz = Sim14Ansatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1, image_type : 4, output_type : 1},  n_layers=1)\n",
    "\n",
    "# Incorrect prepositional phrases found in the diagrams\n",
    "def generate_valid_circuits(conc_diagrams, df):\n",
    "    print(\"************************\")\n",
    "    indicies_to_drop = []\n",
    "    conc_circuit = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            temp = ansatz(conc_diagrams[index])\n",
    "            conc_circuit.append(temp)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index in diagram sentence {index}: {e}\")\n",
    "            # print( \"    \",df[\"sentence\"].iloc[index])\n",
    "            indicies_to_drop.append(index)\n",
    "    # print(\"************************\")\n",
    "\n",
    "    # print(\"************************\")\n",
    "    for index, row in df.iterrows():\n",
    "        if index in indicies_to_drop:\n",
    "            # print(\"Removing index: \", index)\n",
    "            df = df.drop(index = index)\n",
    "    # print(\"************************\")\n",
    "\n",
    "    print(\"Dropped the following indicies:\", indicies_to_drop)\n",
    "    \n",
    "    return df, conc_circuit\n",
    "\n",
    "train_df, train_conc_circuits = generate_valid_circuits(train_conc_diagrams, train_df)\n",
    "val_df, val_conc_circuits = generate_valid_circuits(val_conc_diagrams, val_df)\n",
    "test_df, test_conc_circuits = generate_valid_circuits(test_conc_diagrams, test_df)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(\"CHCEKING:\")\n",
    "print(f\"  (118) {len(train_df)} == {len(train_conc_circuits)}\")\n",
    "print(f\"  (27)  {len(val_df)} == {len(val_conc_circuits)}\")\n",
    "print(f\"  (30)  {len(test_df)} == {len(test_conc_circuits)}\")\n",
    "\n",
    "print(' ↓ template merged circuit : (sentence, image1, image2)')\n",
    "train_conc_circuits[15].draw(figsize=(60, 40), fontsize=18, draw_type_labels = False )\n",
    "\n",
    "print(\"\")\n",
    "print(f\"\\n(*) Train: {len(train_conc_circuits)} circuits completed successfully!\")\n",
    "print(f\"(*) Val: {len(val_conc_circuits)} circuits completed successfully!\")\n",
    "print(f\"(*) Test: {len(test_conc_circuits)} circuits completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Circuit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_circuit = image_1 @ image_2 >> temp_circuit\n",
    "\n",
    "train_final_circuit = [(train_circuits_image1[index] @ train_circuits_image2[index] >> train_conc_circuits[index]) for index in range(len(train_df))]\n",
    "val_final_circuit = [(val_circuits_image1[index] @ val_circuits_image2[index] >> val_conc_circuits[index]) for index in range(len(val_df))]\n",
    "test_final_circuit = [(test_circuits_image1[index] @ test_circuits_image2[index] >> test_conc_circuits[index]) for index in range(len(test_df))]\n",
    "\n",
    "print(\"  ↓ sample quantum circuit : (sentence, image data pos , image data neg)\")\n",
    "train_final_circuit[0].draw(figsize=(30, 15), fontsize=4, draw_type_labels = False )\n",
    "\n",
    "print(f\"\\n(*) Train: {len(train_final_circuit)} circuits completed successfully!\")\n",
    "print(f\"(*) Val:{len(val_final_circuit)} circuits completed successfully!\")\n",
    "print(f\"(*) Test: {len(test_final_circuit)} circuits completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding a labels row\n",
    "\n",
    "-> SHOUDL MOVE THIS TO DATASET SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['labels'] = train_df.apply(lambda row: (row['label_image1'], row['label_image2']), axis=1)\n",
    "val_df['labels'] = val_df.apply(lambda row: (row['label_image1'], row['label_image2']), axis=1)\n",
    "test_df['labels'] = test_df.apply(lambda row: (row['label_image1'], row['label_image2']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Quantum Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is taken from [7] onwords https://cqcl.github.io/lambeq/examples/quantum-pipeline-jax.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a custom loss function that handles multi-output\n",
    "# def custom_loss(y_hat, y):\n",
    "#     # Reshape y to match y_hat  \n",
    "#     y = y.squeeze(axis=1)\n",
    "\n",
    "#     print(\"Loss function\")\n",
    "\n",
    "#     # print(f\"y_hat shape: {y_hat.shape}, y shape: {y.shape}\")\n",
    "#     # print(f\"y1 = {y_hat}, y2 = {y}\")\n",
    "\n",
    "#     loss = BinaryCrossEntropyLoss(use_jax=True)(y_hat, y)\n",
    "#     return loss\n",
    "\n",
    "# # Custom accuracy function for multi-output\n",
    "# def custom_acc(y_hat, y):\n",
    "#     # Rounding predictions to nearest integer to get binary predictions\n",
    "#     y_hat_rounded = np.round(y_hat)\n",
    "    \n",
    "#     # Calculate accuracy for each output separately\n",
    "#     correct_predictions = (y_hat_rounded == y)\n",
    "#     accuracy_per_output = np.mean(correct_predictions, axis=0)\n",
    "    \n",
    "#     # Average accuracy across both outputs\n",
    "#     mean_accuracy = np.mean(accuracy_per_output)\n",
    "    \n",
    "#     return mean_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model \n",
    "from lambeq import NumpyModel\n",
    "from lambeq import BinaryCrossEntropyLoss\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import Dataset\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import jax\n",
    "\n",
    "print(\"Variables\")\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 3e-2\n",
    "EPOCHS = 200\n",
    "SEED = 0\n",
    "\n",
    "print(\"Definitions\")\n",
    "# Labels\n",
    "train_labels = np.array([[label] for label in train_df['labels']]).squeeze(axis=1)\n",
    "val_labels = np.array([[label] for label in val_df['labels']]).squeeze(axis=1)\n",
    "test_labels = np.array([[label] for label in test_df['labels']]).squeeze(axis=1)\n",
    "\n",
    "# Circuits\n",
    "all_circuits = train_final_circuit + val_final_circuit + test_final_circuit\n",
    "\n",
    "print(\"Model\")\n",
    "model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "bce = BinaryCrossEntropyLoss(use_jax=True)\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(y_hat, y):\n",
    "    return np.sum(np.round(y_hat) == y) / len(y)\n",
    "\n",
    "# F1 score function\n",
    "def f1(y_hat, y):\n",
    "    y_hat_rounded = np.round(y_hat)\n",
    "    return f1_score(y, y_hat_rounded, average='weighted')\n",
    "\n",
    "# Precision function\n",
    "def precision(y_hat, y):\n",
    "    y_hat_rounded = np.round(y_hat)\n",
    "    return precision_score(y, y_hat_rounded, average='weighted')\n",
    "\n",
    "# Recall function\n",
    "def recall(y_hat, y):\n",
    "    y_hat_rounded = np.round(y_hat)\n",
    "    return recall_score(y, y_hat_rounded, average='weighted')\n",
    "\n",
    "# F1 score function\n",
    "def f1(y_hat, y):\n",
    "    y_hat_rounded = np.round(y_hat)\n",
    "    return f1_score(y, y_hat_rounded, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Initialize the trainer\")\n",
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=bce,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    # optim_hyperparams={'a': 0.2, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    optim_hyperparams = {'a': 0.02, 'c': 0.06, 'A': 0.001 * EPOCHS},\n",
    "    evaluate_functions={'acc': accuracy, 'f1': f1, 'precision': precision, 'recall': recall},\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "# a : step size in the parameter space during each update\n",
    "# c : size of the perturbations used to approximate the gradient\n",
    "# A : affects the decay of the learning rate over time\n",
    "\n",
    "print(\"Dataset\")\n",
    "train_dataset = Dataset(train_final_circuit, train_labels, batch_size=BATCH_SIZE)\n",
    "val_dataset = Dataset(val_final_circuit, val_labels, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RE-RUN EVERTHING FROM HERE ON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# # Define the checkpoint callback\n",
    "# checkpoint_cb = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# # Fit the model\n",
    "# trainer.fit(train_dataset, val_dataset, callbacks=[checkpoint_cb], log_interval=10)\n",
    "\n",
    "trainer.fit(train_dataset, val_dataset, log_interval=20)\n",
    "# best_model = tf.keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Validation set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "range_ = np.arange(1, trainer.epochs + 1)\n",
    "ax_tl.plot(range_, trainer.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(range_, trainer.train_eval_results['acc'], color=next(colours))\n",
    "ax_tr.plot(range_, trainer.val_costs, color=next(colours))\n",
    "ax_br.plot(range_, trainer.val_eval_results['acc'], color=next(colours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ((ax_tl, ax_tr), (ax_ml, ax_mr), (ax_bl, ax_br) ) = plt.subplots(3, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Validation set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "\n",
    "ax_tl.set_ylabel('F1 Score')\n",
    "ax_ml.set_ylabel('Precision')\n",
    "ax_bl.set_ylabel('Recall')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "range_ = np.arange(1, trainer.epochs + 1)\n",
    "\n",
    "ax_tl.plot(range_, trainer.train_eval_results['f1'], color=next(colours)) # F1 score\n",
    "ax_ml.plot(range_, trainer.train_eval_results['precision'], color=next(colours)) # Precision\n",
    "ax_bl.plot(range_, trainer.train_eval_results['recall'], color=next(colours)) #Recall\n",
    "\n",
    "ax_tr.plot(range_, trainer.val_eval_results['f1'], color=next(colours)) # F1 score\n",
    "ax_mr.plot(range_, trainer.val_eval_results['precision'], color=next(colours)) # Precision\n",
    "ax_br.plot(range_, trainer.val_eval_results['recall'], color=next(colours)) # Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "test_acc = acc(model(test_final_circuit), np.array(test_labels))\n",
    "test_f1 = f1(model(test_final_circuit), np.array(test_labels))\n",
    "test_precision = precision(model(test_final_circuit), np.array(test_labels))\n",
    "test_recall = recall(model(test_final_circuit), np.array(test_labels))\n",
    "\n",
    "# Print results neatly formatted as percentages\n",
    "print(\"* Test Results *\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"Accuracy: {test_acc * 100:.2f}%\")\n",
    "print(f\"F1 Score: {test_f1 * 100:.2f}%\")\n",
    "print(f\"Precision: {test_precision * 100:.2f}%\")\n",
    "print(f\"Test Recall: {test_recall * 100:.2f}%\")\n",
    "print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXCERSIZE: sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "length = len(train_final_circuit)\n",
    "sample_input = train_final_circuit[0:length]  # Assuming train_final_circuit contains circuits\n",
    "\n",
    "for index in range(length):\n",
    "    sample_output = model(sample_input[index:index + 1])\n",
    "    predicted = np.round(sample_output).astype(int).flatten()\n",
    "    label = train_labels[index].astype(int)\n",
    "\n",
    "    print(f\"Probability: {sample_output}\")\n",
    "    print(f\"Predicted: {predicted} | Label: {label}\")\n",
    "\n",
    "    if np.array_equal(predicted, label):\n",
    "        print(\"Correct!\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(\"Incorrect\")\n",
    "        incorrect += 1\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(f\"Correct values = {correct}\")\n",
    "print(f\"Incorrect values = {incorrect}\")\n",
    "print(f\"Total values = \", length)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
